# üß† XAI Brain Tumor Segmentation

This project performs brain tumor segmentation and classification on MRI images using a U-Net-based deep learning model. It integrates Explainable AI (XAI) techniques to provide insights into model predictions,
enhancing trust in medical AI applications. The repository includes preprocessing scripts, model training, and four XAI methods (Grad-CAM, LIME, SHAP, DeepLIFT, etc....) applied across models developed by four students.

---
## üìå Features

- ‚úÖ U-Net model for brain tumor segmentation
- üß™ Preprocessing pipeline for MRI images (grayscale, normalization, CLAHE, resizing)
- üß† Four XAI techniques: Grad-CAM, LIME, SHAP, Deep Lift, etc....
- üñºÔ∏è Visualization scripts for segmented masks and XAI heatmaps
- üóÇÔ∏è Model checkpoints managed with [Git LFS](https://git-lfs.github.com/)

## üß∞ Requirements

Install dependencies:

If using PyTorch, install:

```bash
pip install torch torchvision
```

Additional dependencies for XAI and feature extraction:

```bash
pip install lime captum shap scikit-image
```

---
## üöÄ Usage

1. **Clone the repository**:
   ```bash
   git clone https://github.com/YA195/XAI-Brain-Tumor.git
   cd XAI-Brain-Tumor
   ```

2. **Pull model weights (LFS)**:
   ```bash
   git lfs pull
   ```

3. **Run preprocessing**:
   - Place MRI images and masks in `archive (3)/brats18/images` and `archive (3)/brats18/masks`.
   - Run the preprocessing script to generate preprocessed data:
     ```bash
     python src/preprocess.py
     ```

4. **Run inference**:
   - Use a student's model (e.g., `student1 models/unet_segmentation.pth`):
   - Segmented mask
   - XAI visualizations (Grad-CAM, LIME, SHAP, DeepLIFT heatmaps)

---

## üß† Explainable AI (XAI)

The project implements four XAI techniques to interpret model predictions:

- **Grad-CAM**: Highlights regions of the MRI image influencing the segmentation.
- **LIME**: Identifies key image segments contributing to predictions.
- **SHAP**: Quantifies pixel importance for model output.
- **DeepLIFT**: Computes pixel contributions relative to a baseline.

Each student's folder (`student1 Models`, `student2 Models`, etc.) contains three models, each optimized with 4 of these XAI techniques.

**Dataset**: BraTS18 

**Samples prediction with heatmap**:  


![98a048d2-c6b9-481a-b25a-f72c04b7e1f2](https://github.com/user-attachments/assets/053d4714-35d5-4154-9843-a608a6ffc8da)
![e82d2436-1eb7-4da4-ae7e-b1a6602eeecb](https://github.com/user-attachments/assets/ba861ba2-8213-4dc6-842f-4433696010bb)



1. **Prepare the dataset**:
   - Place MRI images and masks in `archive (3)/brats18/images` and `archive (3)/brats18/masks`.
   - Run preprocessing to generate `preprocessed_images/`:


2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the training cells**:
   - Run the model and train if you want or use saved model's params at "modelexample.pth" if exist 

4. **Run the XAI techniques**:
   - IN the same notebook of the model choose the technique and run it


## ü§ù Contributors

We welcome contributions to improve this project! To contribute:

1. Fork the repository.
2. Create a feature branch (`git checkout -b feature/YourFeature`).
3. Commit your changes (`git commit -m "Add YourFeature"`).
4. Push to the branch (`git push origin feature/YourFeature`).
5. Open a Pull Request.

## üßë‚Äçüíª Author

Youssef Ahmed.  
GitHub: [@YA195](https://github.com/YA195)

---

